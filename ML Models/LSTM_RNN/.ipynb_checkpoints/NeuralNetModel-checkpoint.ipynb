{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import tensorflow as tf\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/luisaguilar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_info_grab(ticker):\n",
    "    \"\"\"\n",
    "    Takes ticker symbol and returns DataFrame with Date, Close, and Pct Change columns.\n",
    "    \"\"\"\n",
    "    # Set timeframe to '1D'\n",
    "    timeframe = \"1D\"\n",
    "\n",
    "    # Set current date and the date from one month ago using the ISO format\n",
    "    current_date = pd.Timestamp(\"2020-11-09\", tz=\"America/New_York\").isoformat()\n",
    "    past_date = pd.Timestamp(\"2016-08-27\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    df = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit=None,\n",
    "        start=past_date,\n",
    "        end=current_date,\n",
    "        after=None,\n",
    "        until=None,\n",
    "    ).df\n",
    "    df = df.droplevel(axis=1, level=0)\n",
    "    df.index = df.index.date\n",
    "    df['pct change'] = df['close'].pct_change()\n",
    "    df['pct change'].dropna\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['open', 'high', 'low', 'volume'])\n",
    "    df = df.rename(columns={'index':'Date'})\n",
    "    df = df.set_index('Date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>106.820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close  pct change\n",
       "Date                           \n",
       "2016-08-29  106.820         NaN\n",
       "2016-08-30  105.990   -0.007770\n",
       "2016-08-31  106.110    0.001132\n",
       "2016-09-01  106.730    0.005843\n",
       "2016-09-02  107.730    0.009369\n",
       "...             ...         ...\n",
       "2020-11-03  110.375    0.014756\n",
       "2020-11-04  114.940    0.041359\n",
       "2020-11-05  118.990    0.035236\n",
       "2020-11-06  118.685   -0.002563\n",
       "2020-11-09  116.320   -0.019927\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_stock_info = stock_info_grab(\"AAPL\")\n",
    "#btc_stock_info = stock_info_grab(\"BTC\") - AMAZON\n",
    "tsla_stock_info = stock_info_grab(\"TSLA\")\n",
    "spy_stock_info = stock_info_grab(\"SPY\")\n",
    "aapl_stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>Nov. 9, 2020 at 4:30 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>Nov. 9, 2020 at 1:45 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>Nov. 9, 2020 at 1:18 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>Nov. 6, 2020 at 9:21 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>Nov. 7, 2020 at 8:49 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>Aug. 29, 2016 at 11:47 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>Aug. 29, 2016 at 9:41 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>Aug. 28, 2016 at 9:15 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>Aug. 27, 2016 at 11:02 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>Aug. 27, 2016 at 10:08 a.m. ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  \\\n",
       "0     Apple Inc. stock falls Monday, underperforms m...   \n",
       "1     Big Tech Stocks Are Lagging Today. Why They’ll...   \n",
       "2     As Apple releases its new line of Macs, the bi...   \n",
       "3     In the Midst of Election Uncertainty, Younger ...   \n",
       "4     Berkshire Buybacks Hit Record $9 Billion in Th...   \n",
       "...                                                 ...   \n",
       "9868  Respect for America has climbed during the Oba...   \n",
       "9869  Fitbit upgrades now track yoga, weightlifting ...   \n",
       "9870  5 things Tim Cook has done better at Apple tha...   \n",
       "9871  Want to invest in self-driving cars? Check out...   \n",
       "9872  As Apple’s ‘death cross’ turns 1, the stock he...   \n",
       "\n",
       "                                Date  \n",
       "0       Nov. 9, 2020 at 4:30 p.m. ET  \n",
       "1       Nov. 9, 2020 at 1:45 p.m. ET  \n",
       "2       Nov. 9, 2020 at 1:18 p.m. ET  \n",
       "3       Nov. 6, 2020 at 9:21 p.m. ET  \n",
       "4       Nov. 7, 2020 at 8:49 a.m. ET  \n",
       "...                              ...  \n",
       "9868  Aug. 29, 2016 at 11:47 a.m. ET  \n",
       "9869   Aug. 29, 2016 at 9:41 a.m. ET  \n",
       "9870   Aug. 28, 2016 at 9:15 p.m. ET  \n",
       "9871  Aug. 27, 2016 at 11:02 a.m. ET  \n",
       "9872  Aug. 27, 2016 at 10:08 a.m. ET  \n",
       "\n",
       "[9873 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_file = Path('../Resources/AAPL_HEADLINES.csv')\n",
    "#btc_file = Path('Resources/BTCUSA_HEADLINES.csv')\n",
    "spy_file = Path('../Resources/SPY_HEADLINES.csv')\n",
    "tsla_file = Path('../Resources/TSLA_HEADLINES.csv')\n",
    "\n",
    "aapl_headlines_df = pd.read_csv(aapl_file)\n",
    "#btc_headlines_df = pd.read_csv(btc_file)\n",
    "spy_headlines_df = pd.read_csv(spy_file)\n",
    "tsla_headlines_df = pd.read_csv(tsla_file)\n",
    "\n",
    "#aapl_headlines['Date'] = pd.to_datetime(aapl_headlines['Date']).dt.strftime('%Y-%m-%d')\n",
    "#aapl_headlines = aapl_headlines.set_index('Date')\n",
    "aapl_headlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_df(df):\n",
    "    \"\"\"\n",
    "    Takes headlines DataFrame & creates DataFrame with Sentiment columns.\n",
    "    Splits Date & Time, creates Time column and moves Date to Index.\n",
    "    \"\"\"\n",
    "    title_sent = {\n",
    "        \"compound\": [],\n",
    "        \"positive\": [],\n",
    "        \"neutral\": [],\n",
    "        \"negative\": [],\n",
    "        \"sentiment\": [],\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Sentiment scoring with VADER\n",
    "            title_sentiment = analyzer.polarity_scores(row[\"Headline\"])\n",
    "            title_sent[\"compound\"].append(title_sentiment[\"compound\"])\n",
    "            title_sent[\"positive\"].append(title_sentiment[\"pos\"])\n",
    "            title_sent[\"neutral\"].append(title_sentiment[\"neu\"])\n",
    "            title_sent[\"negative\"].append(title_sentiment[\"neg\"])\n",
    "            title_sent[\"sentiment\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    title_sent_df = pd.DataFrame(title_sent)\n",
    "    #title_sent_df.head()\n",
    "\n",
    "    headline_sentiment_df = df.join(title_sent_df)\n",
    "    headline_sentiment_df.dropna()\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.replace('at','-')\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.split('-').str[0]\n",
    "    headline_sentiment_df = headline_sentiment_df.reindex(columns=['Date', 'Headline', 'compound', 'positive', 'neutral', 'negative', 'sentiment'])\n",
    "    headline_sentiment_df['Date'] = pd.to_datetime(headline_sentiment_df['Date'])\n",
    "    headline_sentiment_df.set_index('Date')\n",
    "    return headline_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                           Headline  compound  \\\n",
       "0    2020-11-09  Apple Inc. stock falls Monday, underperforms m...    0.0000   \n",
       "1    2020-11-09  Big Tech Stocks Are Lagging Today. Why They’ll...   -0.0772   \n",
       "2    2020-11-09  As Apple releases its new line of Macs, the bi...    0.4767   \n",
       "3    2020-11-06  In the Midst of Election Uncertainty, Younger ...   -0.3400   \n",
       "4    2020-11-07  Berkshire Buybacks Hit Record $9 Billion in Th...   -0.1531   \n",
       "...         ...                                                ...       ...   \n",
       "9868 2016-08-29  Respect for America has climbed during the Oba...    0.4767   \n",
       "9869 2016-08-29  Fitbit upgrades now track yoga, weightlifting ...    0.0000   \n",
       "9870 2016-08-28  5 things Tim Cook has done better at Apple tha...    0.4404   \n",
       "9871 2016-08-27  Want to invest in self-driving cars? Check out...    0.0772   \n",
       "9872 2016-08-27  As Apple’s ‘death cross’ turns 1, the stock he...    0.0000   \n",
       "\n",
       "      positive  neutral  negative  sentiment  \n",
       "0        0.000    1.000     0.000          0  \n",
       "1        0.121    0.738     0.141         -1  \n",
       "2        0.193    0.807     0.000          1  \n",
       "3        0.000    0.806     0.194         -1  \n",
       "4        0.000    0.882     0.118         -1  \n",
       "...        ...      ...       ...        ...  \n",
       "9868     0.279    0.721     0.000          1  \n",
       "9869     0.000    1.000     0.000          0  \n",
       "9870     0.209    0.791     0.000          1  \n",
       "9871     0.126    0.874     0.000          1  \n",
       "9872     0.000    1.000     0.000          0  \n",
       "\n",
       "[9873 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_headlines = create_sentiment_df(aapl_headlines_df)\n",
    "#btc_headlines = create_sentiment_df(btc_headlines_df)\n",
    "tsla_headlines = create_sentiment_df(tsla_headlines_df)\n",
    "spy_headlines = create_sentiment_df(spy_headlines_df)\n",
    "aapl_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.304967</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07</th>\n",
       "      <td>-0.153100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment\n",
       "Date                                                         \n",
       "2016-03-19  0.836000  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.038600  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.440400  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.067100  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909\n",
       "...              ...       ...       ...       ...        ...\n",
       "2020-11-04 -0.038410  0.078900  0.800900  0.120300  -0.300000\n",
       "2020-11-05  0.304967  0.202333  0.747333  0.050333   0.333333\n",
       "2020-11-06 -0.099333  0.054833  0.845500  0.099500  -0.500000\n",
       "2020-11-07 -0.153100  0.000000  0.882000  0.118000  -1.000000\n",
       "2020-11-09  0.133167  0.104667  0.848333  0.047000   0.000000\n",
       "\n",
       "[1410 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find average sentiment score by date\n",
    "aapl_scores = aapl_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "#btc_scores = btc_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "tsla_scores = tsla_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "spy_scores = spy_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "aapl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.99</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>-0.043420</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.11</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.73</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>-0.087129</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.73</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.70</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>0.088762</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>108.37</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.069714</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.067929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.51</td>\n",
       "      <td>-0.026391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-09</th>\n",
       "      <td>-0.059275</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.872750</td>\n",
       "      <td>0.077750</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>103.14</td>\n",
       "      <td>-0.022462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-12</th>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>105.44</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-13</th>\n",
       "      <td>0.079327</td>\n",
       "      <td>0.089818</td>\n",
       "      <td>0.888455</td>\n",
       "      <td>0.021818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>108.02</td>\n",
       "      <td>0.024469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment   close  \\\n",
       "Date                                                                    \n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909  105.99   \n",
       "2016-08-31 -0.043420  0.070400  0.818600  0.111000  -0.200000  106.11   \n",
       "2016-09-01  0.009625  0.069625  0.897625  0.032750   0.125000  106.73   \n",
       "2016-09-02 -0.087129  0.063143  0.845429  0.091429  -0.285714  107.73   \n",
       "2016-09-06  0.093200  0.131750  0.804500  0.063750   0.250000  107.70   \n",
       "2016-09-07  0.088762  0.096000  0.877000  0.027000   0.250000  108.37   \n",
       "2016-09-08  0.010821  0.069714  0.862357  0.067929   0.000000  105.51   \n",
       "2016-09-09 -0.059275  0.049500  0.872750  0.077750  -0.250000  103.14   \n",
       "2016-09-12  0.158900  0.113000  0.887000  0.000000   0.333333  105.44   \n",
       "2016-09-13  0.079327  0.089818  0.888455  0.021818   0.272727  108.02   \n",
       "\n",
       "            pct change  \n",
       "Date                    \n",
       "2016-08-30   -0.007770  \n",
       "2016-08-31    0.001132  \n",
       "2016-09-01    0.005843  \n",
       "2016-09-02    0.009369  \n",
       "2016-09-06   -0.000278  \n",
       "2016-09-07    0.006221  \n",
       "2016-09-08   -0.026391  \n",
       "2016-09-09   -0.022462  \n",
       "2016-09-12    0.022300  \n",
       "2016-09-13    0.024469  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_complete = pd.concat([aapl_scores,aapl_stock_info], join='outer', axis=1).dropna()\n",
    "#btc_complete = pd.concat([btc_scores,btc_stock_info], join='outer', axis=1).dropna()\n",
    "tsla_complete = pd.concat([tsla_scores,tsla_stock_info], join='outer', axis=1).dropna()\n",
    "spy_complete = pd.concat([spy_scores,spy_stock_info], join='outer', axis=1).dropna()\n",
    "aapl_complete.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09090909],\n",
       "       [-0.2       ],\n",
       "       [ 0.125     ],\n",
       "       [-0.28571429],\n",
       "       [ 0.25      ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features data\n",
    "X = df['sentiment'].values\n",
    "X = X.reshape(-1, 1)\n",
    "#X = X.drop(columns=[\"pct change\"])\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00777008],\n",
       "       [ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target data\n",
    "y = df[\"pct change\"].values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 5\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.0013\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.0038\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.0038\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.0038\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.0038\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1840 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1560 - accuracy: 0.0038\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.0038\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.0038\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.0038\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.0038\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.0038\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0217 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.0038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.0038\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.0038\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.0038\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.0038\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.0038 ETA: 0s - loss: 0.0090 - accuracy: 0.00\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.0038\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.0038\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.0038\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.0038 ETA: 0s - loss: 0.0254 - accuracy: 0.0104\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe with the history dictionary\n",
    "df_plot = pd.DataFrame(model.history, index=range(1, len(model.history[\"loss\"]) + 1))\n",
    "\n",
    "# Plot the loss\n",
    "df_plot.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "df_plot.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0161 - accuracy: 0.0000e+00\n",
      "Loss: 0.016056545078754425, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with \"Hard Sigmoid\" activation\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 120\n",
    "\n",
    "nn_2 = Sequential()\n",
    "nn_2.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"tanh\"))\n",
    "nn_2.add(Dense(units=1, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6263 - accuracy: 0.0038\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.0038 - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0377 - accuracy: 0.0000e+00\n",
      "Loss: 0.037722621113061905, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss_2, model_accuracy_2 = nn_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss_2}, Accuracy: {model_accuracy_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"pct change\"]\n",
    "X = df.drop(columns=\"pct change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c9d8dbe3fb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                    stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1669\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[-0.00777008  0.00113218  0.00584299  0.00936944 -0.00027847]\n",
      " [ 0.00113218  0.00584299  0.00936944 -0.00027847  0.00622098]\n",
      " [ 0.00584299  0.00936944 -0.00027847  0.00622098 -0.02639107]\n",
      " [ 0.00936944 -0.00027847  0.00622098 -0.02639107 -0.02246233]\n",
      " [-0.00027847  0.00622098 -0.02639107 -0.02246233  0.02229979]] \n",
      "\n",
      "y sample values:\n",
      "[[ 0.00622098]\n",
      " [-0.02639107]\n",
      " [-0.02246233]\n",
      " [ 0.02229979]\n",
      " [ 0.02446889]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 6\n",
    "target_column = 6\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = aapl_complete[\"Headline\"].values\n",
    "#y = aapl_sentiment[\"close\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>-0.043420</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>-0.087129</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.304967</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment    close\n",
       "Date                                                                  \n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909  105.990\n",
       "2016-08-31 -0.043420  0.070400  0.818600  0.111000  -0.200000  106.110\n",
       "2016-09-01  0.009625  0.069625  0.897625  0.032750   0.125000  106.730\n",
       "2016-09-02 -0.087129  0.063143  0.845429  0.091429  -0.285714  107.730\n",
       "2016-09-06  0.093200  0.131750  0.804500  0.063750   0.250000  107.700\n",
       "...              ...       ...       ...       ...        ...      ...\n",
       "2020-11-03  0.181500  0.119000  0.842000  0.038833   0.500000  110.375\n",
       "2020-11-04 -0.038410  0.078900  0.800900  0.120300  -0.300000  114.940\n",
       "2020-11-05  0.304967  0.202333  0.747333  0.050333   0.333333  118.990\n",
       "2020-11-06 -0.099333  0.054833  0.845500  0.099500  -0.500000  118.685\n",
       "2020-11-09  0.133167  0.104667  0.848333  0.047000   0.000000  116.320\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "x_cols = [i for i in aapl_complete.columns if i not in (\"pct change\")]\n",
    "X = aapl_complete[x_cols]\n",
    "y = aapl_complete[\"pct change\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "#tokenizer = Tokenizer(lower=True)\n",
    "#tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "#for token in list(tokenizer.word_index)[:5]:\n",
    "    #print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "#X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "#print(\"**Text comment**\")\n",
    "#print({X[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"**Numerical sequence representation**\")\n",
    "#print(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "#max_words = 30\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "#X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "#X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "#X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "#vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "#embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "#model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 64)            3328      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 1400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 4,734\n",
      "Trainable params: 4,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7537 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7529 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7302 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7189 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7071 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6854 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6844 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6521 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6619 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6189 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6395 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.5858 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6172 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5527 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5949 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5196 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5728 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4865 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5506 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4532 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ecc8dedd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN LSTM Accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-13207cb38487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrtix metrics from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rnn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dataframe to display confusion matrix from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_rnn_df = pd.DataFrame(\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve (AUC=1.0)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
