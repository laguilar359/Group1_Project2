{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import tensorflow as tf\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/luisaguilar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_info_grab(ticker):\n",
    "    \"\"\"\n",
    "    Takes ticker symbol and returns DataFrame with Date, Close, and Pct Change columns.\n",
    "    \"\"\"\n",
    "    # Set timeframe to '1D'\n",
    "    timeframe = \"1D\"\n",
    "\n",
    "    # Set current date and the date from one month ago using the ISO format\n",
    "    current_date = pd.Timestamp(\"2020-11-09\", tz=\"America/New_York\").isoformat()\n",
    "    past_date = pd.Timestamp(\"2016-08-27\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    df = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit=None,\n",
    "        start=past_date,\n",
    "        end=current_date,\n",
    "        after=None,\n",
    "        until=None,\n",
    "    ).df\n",
    "    df = df.droplevel(axis=1, level=0)\n",
    "    df.index = df.index.date\n",
    "    df['pct change'] = df['close'].pct_change()\n",
    "    df['pct change'].dropna\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['open', 'high', 'low', 'volume'])\n",
    "    df = df.rename(columns={'index':'Date'})\n",
    "    df = df.set_index('Date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>106.820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close  pct change\n",
       "Date                           \n",
       "2016-08-29  106.820         NaN\n",
       "2016-08-30  105.990   -0.007770\n",
       "2016-08-31  106.110    0.001132\n",
       "2016-09-01  106.730    0.005843\n",
       "2016-09-02  107.730    0.009369\n",
       "...             ...         ...\n",
       "2020-11-03  110.375    0.014756\n",
       "2020-11-04  114.940    0.041359\n",
       "2020-11-05  118.990    0.035236\n",
       "2020-11-06  118.685   -0.002563\n",
       "2020-11-09  116.320   -0.019927\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_stock_info = stock_info_grab(\"AAPL\")\n",
    "amzn_stock_info = stock_info_grab(\"AMZN\")\n",
    "tsla_stock_info = stock_info_grab(\"TSLA\")\n",
    "spy_stock_info = stock_info_grab(\"SPY\")\n",
    "aapl_stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>Nov. 9, 2020 at 4:30 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>Nov. 9, 2020 at 1:45 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>Nov. 9, 2020 at 1:18 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>Nov. 6, 2020 at 9:21 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>Nov. 7, 2020 at 8:49 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>Aug. 29, 2016 at 11:47 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>Aug. 29, 2016 at 9:41 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>Aug. 28, 2016 at 9:15 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>Aug. 27, 2016 at 11:02 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>Aug. 27, 2016 at 10:08 a.m. ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  \\\n",
       "0     Apple Inc. stock falls Monday, underperforms m...   \n",
       "1     Big Tech Stocks Are Lagging Today. Why They’ll...   \n",
       "2     As Apple releases its new line of Macs, the bi...   \n",
       "3     In the Midst of Election Uncertainty, Younger ...   \n",
       "4     Berkshire Buybacks Hit Record $9 Billion in Th...   \n",
       "...                                                 ...   \n",
       "9868  Respect for America has climbed during the Oba...   \n",
       "9869  Fitbit upgrades now track yoga, weightlifting ...   \n",
       "9870  5 things Tim Cook has done better at Apple tha...   \n",
       "9871  Want to invest in self-driving cars? Check out...   \n",
       "9872  As Apple’s ‘death cross’ turns 1, the stock he...   \n",
       "\n",
       "                                Date  \n",
       "0       Nov. 9, 2020 at 4:30 p.m. ET  \n",
       "1       Nov. 9, 2020 at 1:45 p.m. ET  \n",
       "2       Nov. 9, 2020 at 1:18 p.m. ET  \n",
       "3       Nov. 6, 2020 at 9:21 p.m. ET  \n",
       "4       Nov. 7, 2020 at 8:49 a.m. ET  \n",
       "...                              ...  \n",
       "9868  Aug. 29, 2016 at 11:47 a.m. ET  \n",
       "9869   Aug. 29, 2016 at 9:41 a.m. ET  \n",
       "9870   Aug. 28, 2016 at 9:15 p.m. ET  \n",
       "9871  Aug. 27, 2016 at 11:02 a.m. ET  \n",
       "9872  Aug. 27, 2016 at 10:08 a.m. ET  \n",
       "\n",
       "[9873 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_file = Path('../Resources/AAPL_HEADLINES.csv')\n",
    "#amzn_file = Path('../Resources/AMZN_HEADLINES.csv')\n",
    "spy_file = Path('../Resources/SPY_HEADLINES.csv')\n",
    "tsla_file = Path('../Resources/TSLA_HEADLINES.csv')\n",
    "\n",
    "aapl_headlines_df = pd.read_csv(aapl_file)\n",
    "#amzn_headlines_df = pd.read_csv(amzn_file)\n",
    "spy_headlines_df = pd.read_csv(spy_file)\n",
    "tsla_headlines_df = pd.read_csv(tsla_file)\n",
    "\n",
    "#aapl_headlines['Date'] = pd.to_datetime(aapl_headlines['Date']).dt.strftime('%Y-%m-%d')\n",
    "#aapl_headlines = aapl_headlines.set_index('Date')\n",
    "aapl_headlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_df(df):\n",
    "    \"\"\"\n",
    "    Takes headlines DataFrame & creates DataFrame with Sentiment columns.\n",
    "    Splits Date & Time, creates Time column and moves Date to Index.\n",
    "    \"\"\"\n",
    "    title_sent = {\n",
    "        \"compound\": [],\n",
    "        \"positive\": [],\n",
    "        \"neutral\": [],\n",
    "        \"negative\": [],\n",
    "        \"sentiment\": [],\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Sentiment scoring with VADER\n",
    "            title_sentiment = analyzer.polarity_scores(row[\"Headline\"])\n",
    "            title_sent[\"compound\"].append(title_sentiment[\"compound\"])\n",
    "            title_sent[\"positive\"].append(title_sentiment[\"pos\"])\n",
    "            title_sent[\"neutral\"].append(title_sentiment[\"neu\"])\n",
    "            title_sent[\"negative\"].append(title_sentiment[\"neg\"])\n",
    "            title_sent[\"sentiment\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    title_sent_df = pd.DataFrame(title_sent)\n",
    "    #title_sent_df.head()\n",
    "\n",
    "    headline_sentiment_df = df.join(title_sent_df)\n",
    "    headline_sentiment_df.dropna()\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.replace('at','-')\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.split('-').str[0]\n",
    "    headline_sentiment_df = headline_sentiment_df.reindex(columns=['Date', 'Headline', 'compound', 'positive', 'neutral', 'negative', 'sentiment'])\n",
    "    headline_sentiment_df['Date'] = pd.to_datetime(headline_sentiment_df['Date'])\n",
    "    headline_sentiment_df.set_index('Date')\n",
    "    return headline_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                           Headline  compound  \\\n",
       "0    2020-11-09  Apple Inc. stock falls Monday, underperforms m...    0.0000   \n",
       "1    2020-11-09  Big Tech Stocks Are Lagging Today. Why They’ll...   -0.0772   \n",
       "2    2020-11-09  As Apple releases its new line of Macs, the bi...    0.4767   \n",
       "3    2020-11-06  In the Midst of Election Uncertainty, Younger ...   -0.3400   \n",
       "4    2020-11-07  Berkshire Buybacks Hit Record $9 Billion in Th...   -0.1531   \n",
       "...         ...                                                ...       ...   \n",
       "9868 2016-08-29  Respect for America has climbed during the Oba...    0.4767   \n",
       "9869 2016-08-29  Fitbit upgrades now track yoga, weightlifting ...    0.0000   \n",
       "9870 2016-08-28  5 things Tim Cook has done better at Apple tha...    0.4404   \n",
       "9871 2016-08-27  Want to invest in self-driving cars? Check out...    0.0772   \n",
       "9872 2016-08-27  As Apple’s ‘death cross’ turns 1, the stock he...    0.0000   \n",
       "\n",
       "      positive  neutral  negative  sentiment  \n",
       "0        0.000    1.000     0.000          0  \n",
       "1        0.121    0.738     0.141         -1  \n",
       "2        0.193    0.807     0.000          1  \n",
       "3        0.000    0.806     0.194         -1  \n",
       "4        0.000    0.882     0.118         -1  \n",
       "...        ...      ...       ...        ...  \n",
       "9868     0.279    0.721     0.000          1  \n",
       "9869     0.000    1.000     0.000          0  \n",
       "9870     0.209    0.791     0.000          1  \n",
       "9871     0.126    0.874     0.000          1  \n",
       "9872     0.000    1.000     0.000          0  \n",
       "\n",
       "[9873 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_headlines = create_sentiment_df(aapl_headlines_df)\n",
    "#amzn_headlines = create_sentiment_df(amzn_headlines_df)\n",
    "tsla_headlines = create_sentiment_df(tsla_headlines_df)\n",
    "spy_headlines = create_sentiment_df(spy_headlines_df)\n",
    "aapl_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average sentiment score by date\n",
    "aapl_scores = aapl_headlines.groupby('Date').mean().sort_values(by='Date')\n",
    "#amzn_scores = amzn_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "tsla_scores = tsla_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "spy_scores = spy_headlines.groupby(['Date']).mean().sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment\n",
       "Date                                                         \n",
       "2016-03-19  0.836000  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.038600  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.440400  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.067100  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: drop compund col on all scores\n",
    "aapl_scores = aapl_scores.drop(columns='compound')\n",
    "#amzn_scores = amzn_scores.drop(columns='compound')\n",
    "tsla_scores = tsla_scores.drop(columns='compound')\n",
    "spy_scores = spy_scores.drop(columns='compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change\n",
       "Date                                                                    \n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909  105.990   -0.007770\n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132\n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843\n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369\n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278\n",
       "...              ...       ...       ...        ...      ...         ...\n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756\n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359\n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236\n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563\n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent scores distribution across each df poss use histogram, calc meanstd, or percentiles \n",
    "aapl_complete = pd.concat([aapl_scores,aapl_stock_info], join='outer', axis=1).dropna()\n",
    "#amzn_complete = pd.concat([amzn_scores,amzn_stock_info], join='outer', axis=1).dropna()\n",
    "tsla_complete = pd.concat([tsla_scores,tsla_stock_info], join='outer', axis=1).dropna()\n",
    "spy_complete = pd.concat([spy_scores,spy_stock_info], join='outer', axis=1).dropna()\n",
    "aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: shift aapl_complete['pct change'] one day on all dfs\n",
    "# TO DO: dropna() on all df['predicted pct change'] cols \n",
    "aapl_complete['predicted pct change'] = aapl_complete['pct change'].shift(periods=1)\n",
    "#amzn_complete['predicted pct change'] = amzn_complete['pct change'].shift(periods=1)\n",
    "tsla_complete['predicted pct change'] = tsla_complete['pct change'].shift(periods=1)\n",
    "spy_complete['predicted pct change'] = spy_complete['pct change'].shift(periods=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_complete = aapl_complete.dropna()\n",
    "#amzn_complete = amzn_complete.dropna()\n",
    "tsla_complete = tsla_complete.dropna()\n",
    "spy_complete = spy_complete.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = [\n",
    "        (df['sentiment'] >= 0.10),\n",
    "        (df['sentiment'] > -0.10) & (df['sentiment'] < 0.10),\n",
    "        (df['sentiment'] <= -0.10)\n",
    "    ]\n",
    "    \n",
    "    values = ['sell', 'hold', 'buy']\n",
    "    \n",
    "    df['buy/hold/sell'] = np.select(result, values)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "      <th>predicted pct change</th>\n",
       "      <th>buy/hold/sell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>108.370</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change  \\\n",
       "Date                                                                       \n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132   \n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843   \n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369   \n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278   \n",
       "2016-09-07  0.096000  0.877000  0.027000   0.250000  108.370    0.006221   \n",
       "...              ...       ...       ...        ...      ...         ...   \n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756   \n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359   \n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236   \n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563   \n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927   \n",
       "\n",
       "            predicted pct change buy/hold/sell  \n",
       "Date                                            \n",
       "2016-08-31             -0.007770           buy  \n",
       "2016-09-01              0.001132          sell  \n",
       "2016-09-02              0.005843           buy  \n",
       "2016-09-06              0.009369          sell  \n",
       "2016-09-07             -0.000278          sell  \n",
       "...                          ...           ...  \n",
       "2020-11-03             -0.001194          sell  \n",
       "2020-11-04              0.014756           buy  \n",
       "2020-11-05              0.041359          sell  \n",
       "2020-11-06              0.035236           buy  \n",
       "2020-11-09             -0.002563          hold  \n",
       "\n",
       "[1051 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_complete_sentiment = get_sentiment(aapl_complete)\n",
    "#amzn_complete_sentiment = get_sentiment(amzn_complete)\n",
    "tsla_complete_sentiment = get_sentiment(tsla_complete)\n",
    "spy_complete_sentiment = get_sentiment(spy_complete)\n",
    "aapl_complete_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "      <th>predicted pct change</th>\n",
       "      <th>buy/hold/sell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>108.370</td>\n",
       "      <td>0.006221</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>-0.001194</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change  \\\n",
       "Date                                                                       \n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132   \n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843   \n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369   \n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278   \n",
       "2016-09-07  0.096000  0.877000  0.027000   0.250000  108.370    0.006221   \n",
       "...              ...       ...       ...        ...      ...         ...   \n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756   \n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359   \n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236   \n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563   \n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927   \n",
       "\n",
       "            predicted pct change buy/hold/sell  \n",
       "Date                                            \n",
       "2016-08-31             -0.007770           buy  \n",
       "2016-09-01              0.001132          sell  \n",
       "2016-09-02              0.005843           buy  \n",
       "2016-09-06              0.009369          sell  \n",
       "2016-09-07             -0.000278          sell  \n",
       "...                          ...           ...  \n",
       "2020-11-03             -0.001194          sell  \n",
       "2020-11-04              0.014756           buy  \n",
       "2020-11-05              0.041359          sell  \n",
       "2020-11-06              0.035236           buy  \n",
       "2020-11-09             -0.002563          hold  \n",
       "\n",
       "[1051 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc['2008':'2012']\n",
    "\n",
    "test = df.loc['2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for X_train and X_test\n",
    "# Create series for y_train and y_test\n",
    "# X_train (training set using just the independent variables), X_test (test set of of just the independent variables)\n",
    "# Y_train (training set using just the \"y\" variable, i.e., \"Futures Return\"), Y_test (test set of just the \"y\" variable):\n",
    "X_train = train[\"Lagged_Return\"].to_frame()\n",
    "X_test = test[\"Lagged_Return\"].to_frame()\n",
    "y_train = train[\"Return\"]\n",
    "y_test = test[\"Return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lagged_Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>-0.685159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>-1.443784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>-2.455155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2008-01-08</td>\n",
       "      <td>0.322326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lagged_Return\n",
       "Date                     \n",
       "2008-01-02      -0.685159\n",
       "2008-01-03      -1.443784\n",
       "2008-01-04       0.000000\n",
       "2008-01-07      -2.455155\n",
       "2008-01-08       0.322326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2008-01-02   -1.443784\n",
       "2008-01-03    0.000000\n",
       "2008-01-04   -2.455155\n",
       "2008-01-07    0.322326\n",
       "2008-01-08   -1.835227\n",
       "Name: Return, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit a SKLearn linear regression using  just the training set (X_train, Y_train):\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using the Testing Data\n",
    "\n",
    "Note: We want to evaluate the model using data that it has never seen before, in this case: X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And make a prediction of \"y\" values for just the test dataset\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble actual y data (Y_test) with predicted y data (from just above) into two columns in a dataframe:\n",
    "Results = y_test.to_frame()\n",
    "Results[\"Predicted Return\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>Predicted Return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2.540342</td>\n",
       "      <td>-0.188503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>-0.208562</td>\n",
       "      <td>-0.288921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Return  Predicted Return\n",
       "Date                                  \n",
       "2013-01-02  2.540342         -0.188503\n",
       "2013-01-03 -0.208562         -0.288921"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fa248f94d10>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fa2283a5d50>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first 20 predictions against the true values to see how it performed\n",
    "# The trends lines should be similar\n",
    "Results[:20].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Performance\n",
    "\n",
    "Evaluate the model using \"out-of-sample\" data (X_test and y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Sample Root Mean Squared Error (RMSE): 0.7037691017337323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Calculate the mean_squared_error (MSE) on actual versus predicted test \"y\" \n",
    "# (Hint: use the dataframe above)\n",
    "mse = mean_squared_error(\n",
    "    Results[\"Return\"],\n",
    "    Results[\"Predicted Return\"]\n",
    ")\n",
    "\n",
    "# Using that mean-squared-error, calculate the root-mean-squared error (RMSE):\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Out-of-Sample Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Sample Performance\n",
    "\n",
    "Evaluate the model using in-sample data (X_train and y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample Root Mean Squared Error (RMSE): 1.6450198277763866\n"
     ]
    }
   ],
   "source": [
    "# Construct a dataframe using just the \"y\" training data:\n",
    "in_sample_results = y_train.to_frame()\n",
    "\n",
    "# Add a column of \"in-sample\" predictions to that DataFrame:  \n",
    "in_sample_results[\"In-sample Predictions\"] = model.predict(X_train)\n",
    "\n",
    "# Calculate in-sample mean_squared_error (for comparison to out-of-sample)\n",
    "in_sample_mse = mean_squared_error(\n",
    "    in_sample_results[\"Return\"],\n",
    "    in_sample_results[\"In-sample Predictions\"]\n",
    ")\n",
    "\n",
    "# Calculate in-sample root mean_squared_error (for comparison to out-of-sample)\n",
    "in_sample_rmse = np.sqrt(in_sample_mse)\n",
    "print(f\"In-sample Root Mean Squared Error (RMSE): {in_sample_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Linear Regression Model using sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0704    ,  0.8186    ,  0.111     , -0.2       ],\n",
       "       [ 0.069625  ,  0.897625  ,  0.03275   ,  0.125     ],\n",
       "       [ 0.06314286,  0.84542857,  0.09142857, -0.28571429],\n",
       "       [ 0.13175   ,  0.8045    ,  0.06375   ,  0.25      ],\n",
       "       [ 0.096     ,  0.877     ,  0.027     ,  0.25      ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.copy()\n",
    "X = df[[\"positive\", \"neutral\", \"negative\", \"sentiment\"]].values\n",
    "#X = X.reshape(-1, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.reshape(X.shape[1052, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847],\n",
       "       [ 0.00622098]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = df[\"pct change\"].values\n",
    "#y = df[\"pct change\"].shift(periods=1).values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "results = model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00283651],\n",
       "       [ 0.00211529],\n",
       "       [-0.00210365],\n",
       "       ...,\n",
       "       [ 0.00541104],\n",
       "       [-0.00426934],\n",
       "       [ 0.00511573]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the X data\n",
    "predicted_y_values = model.predict(X)\n",
    "predicted_y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the coef, intercept, and calculate the score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.53245951e+00, -9.55949343e+00, -9.61521617e+00,\n",
       "         1.88447416e-03]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.56131585])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020815761935934374"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 value\n",
    "model.score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2bfba381bbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot X and y as a scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Plot X and the predictions as a red line plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_y_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m         \u001b[0mplotnonfinite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplotnonfinite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2879\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2880\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot X and y as a scatter plot\n",
    "# Plot X and the predictions as a red line plot\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, predicted_y_values, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the coef, intercept, and calculate the score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117841.63757442])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408619.81940216525"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11267062525400562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 value\n",
    "model.score(X, y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06159091,  0.88345455,  0.05495455, -0.09090909],\n",
       "       [ 0.0704    ,  0.8186    ,  0.111     , -0.2       ],\n",
       "       [ 0.069625  ,  0.897625  ,  0.03275   ,  0.125     ],\n",
       "       [ 0.06314286,  0.84542857,  0.09142857, -0.28571429],\n",
       "       [ 0.13175   ,  0.8045    ,  0.06375   ,  0.25      ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.copy()\n",
    "X = df[[\"positive\", \"neutral\", \"negative\", \"sentiment\"]].values\n",
    "#X = X.reshape(-1, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.reshape(X.shape[1052, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847],\n",
       "       [ 0.00622098]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = df[\"predicted pct change\"].values\n",
    "#y = df[\"pct change\"].shift(periods=1).values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-c9d8dbe3fb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                    stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1669\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Create a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Score the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9708121827411168\n",
      "Testing Data Score: 0.9695817490494296\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "#results = pd.DataFrame({\"Prediction\": predictions,\n",
    "                        #\"Actual\": y_test}).reset_index(drop=True)\n",
    "#results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75,   0,   0],\n",
       "       [  3,  48,   5],\n",
       "       [  0,   0, 132]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         buy       0.96      1.00      0.98        75\n",
      "        hold       1.00      0.86      0.92        56\n",
      "        sell       0.96      1.00      0.98       132\n",
      "\n",
      "    accuracy                           0.97       263\n",
      "   macro avg       0.98      0.95      0.96       263\n",
      "weighted avg       0.97      0.97      0.97       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09090909],\n",
       "       [-0.2       ],\n",
       "       [ 0.125     ],\n",
       "       [-0.28571429],\n",
       "       [ 0.25      ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features data\n",
    "#X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"pct change\"])\n",
    "\n",
    "\n",
    "#X[:5]\n",
    "\n",
    "X = df.copy()\n",
    "X =df['sentiment'].values\n",
    "#X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"close\", \"pct change\", \"predicted pct change\"]).values\n",
    "X = X.reshape(-1, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00777008],\n",
       "       [ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target data\n",
    "y = df[\"pct change\"].values\n",
    "#y = df[\"pct change\"].shift(periods=1).values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 4\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.0025\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.0038\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.0038\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.0038\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0038\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0038\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0038 \n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.0038\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.0038e+ - ETA: 0s - loss: 0.0296 - accuracy: 0.0045      \n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.0038\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.0038\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.0038\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.0038 \n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.0038   \n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0038\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0038 \n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0038    \n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0038 - ETA: 0s - loss: 0.0070 - accuracy: 0.0035   \n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.0038 \n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.0038     \n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.0038 \n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.0038 \n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.0038 \n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe with the history dictionary\n",
    "df_plot = pd.DataFrame(model.history, index=range(1, len(model.history[\"loss\"]) + 1))\n",
    "\n",
    "# Plot the loss\n",
    "df_plot.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "df_plot.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0162 - accuracy: 0.0000e+00\n",
      "Loss: 0.016187742352485657, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with \"Hard Sigmoid\" activation\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 120\n",
    "\n",
    "nn_2 = Sequential()\n",
    "nn_2.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"tanh\"))\n",
    "nn_2.add(Dense(units=1, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.0038\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: -0.0012 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038    \n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0377 - accuracy: 0.0000e+00\n",
      "Loss: 0.037722621113061905, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss_2, model_accuracy_2 = nn_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss_2}, Accuracy: {model_accuracy_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"pct change\"]\n",
    "X = df.drop(columns=\"pct change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c9d8dbe3fb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                    stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1669\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[-0.00777008  0.00113218  0.00584299  0.00936944 -0.00027847]\n",
      " [ 0.00113218  0.00584299  0.00936944 -0.00027847  0.00622098]\n",
      " [ 0.00584299  0.00936944 -0.00027847  0.00622098 -0.02639107]\n",
      " [ 0.00936944 -0.00027847  0.00622098 -0.02639107 -0.02246233]\n",
      " [-0.00027847  0.00622098 -0.02639107 -0.02246233  0.02229979]] \n",
      "\n",
      "y sample values:\n",
      "[[ 0.00622098]\n",
      " [-0.02639107]\n",
      " [-0.02246233]\n",
      " [ 0.02229979]\n",
      " [ 0.02446889]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 6\n",
    "target_column = 6\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = aapl_complete[\"Headline\"].values\n",
    "#y = aapl_sentiment[\"close\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>-0.043420</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>-0.087129</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.304967</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment    close\n",
       "Date                                                                  \n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909  105.990\n",
       "2016-08-31 -0.043420  0.070400  0.818600  0.111000  -0.200000  106.110\n",
       "2016-09-01  0.009625  0.069625  0.897625  0.032750   0.125000  106.730\n",
       "2016-09-02 -0.087129  0.063143  0.845429  0.091429  -0.285714  107.730\n",
       "2016-09-06  0.093200  0.131750  0.804500  0.063750   0.250000  107.700\n",
       "...              ...       ...       ...       ...        ...      ...\n",
       "2020-11-03  0.181500  0.119000  0.842000  0.038833   0.500000  110.375\n",
       "2020-11-04 -0.038410  0.078900  0.800900  0.120300  -0.300000  114.940\n",
       "2020-11-05  0.304967  0.202333  0.747333  0.050333   0.333333  118.990\n",
       "2020-11-06 -0.099333  0.054833  0.845500  0.099500  -0.500000  118.685\n",
       "2020-11-09  0.133167  0.104667  0.848333  0.047000   0.000000  116.320\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "x_cols = [i for i in aapl_complete.columns if i not in (\"pct change\")]\n",
    "X = aapl_complete[x_cols]\n",
    "y = aapl_complete[\"pct change\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "#tokenizer = Tokenizer(lower=True)\n",
    "#tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "#for token in list(tokenizer.word_index)[:5]:\n",
    "    #print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "#X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "#print(\"**Text comment**\")\n",
    "#print({X[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"**Numerical sequence representation**\")\n",
    "#print(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "#max_words = 30\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "#X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "#X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "#X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "#vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "#embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "#model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 64)            3328      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 1400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 4,734\n",
      "Trainable params: 4,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7537 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7529 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7302 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7189 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7071 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6854 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6844 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6521 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6619 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6189 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6395 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.5858 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6172 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5527 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5949 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5196 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5728 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4865 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5506 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4532 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ecc8dedd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN LSTM Accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-13207cb38487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrtix metrics from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rnn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dataframe to display confusion matrix from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_rnn_df = pd.DataFrame(\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve (AUC=1.0)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
