{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import tensorflow as tf\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/luisaguilar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_info_grab(ticker):\n",
    "    \"\"\"\n",
    "    Takes ticker symbol and returns DataFrame with Date, Close, and Pct Change columns.\n",
    "    \"\"\"\n",
    "    # Set timeframe to '1D'\n",
    "    timeframe = \"1D\"\n",
    "\n",
    "    # Set current date and the date from one month ago using the ISO format\n",
    "    current_date = pd.Timestamp(\"2020-11-09\", tz=\"America/New_York\").isoformat()\n",
    "    past_date = pd.Timestamp(\"2016-08-27\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    df = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit=None,\n",
    "        start=past_date,\n",
    "        end=current_date,\n",
    "        after=None,\n",
    "        until=None,\n",
    "    ).df\n",
    "    df = df.droplevel(axis=1, level=0)\n",
    "    df.index = df.index.date\n",
    "    df['pct change'] = df['close'].pct_change()\n",
    "    df['pct change'].dropna\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['open', 'high', 'low', 'volume'])\n",
    "    df = df.rename(columns={'index':'Date'})\n",
    "    df = df.set_index('Date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>106.820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              close  pct change\n",
       "Date                           \n",
       "2016-08-29  106.820         NaN\n",
       "2016-08-30  105.990   -0.007770\n",
       "2016-08-31  106.110    0.001132\n",
       "2016-09-01  106.730    0.005843\n",
       "2016-09-02  107.730    0.009369\n",
       "...             ...         ...\n",
       "2020-11-03  110.375    0.014756\n",
       "2020-11-04  114.940    0.041359\n",
       "2020-11-05  118.990    0.035236\n",
       "2020-11-06  118.685   -0.002563\n",
       "2020-11-09  116.320   -0.019927\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_stock_info = stock_info_grab(\"AAPL\")\n",
    "amzn_stock_info = stock_info_grab(\"AMZN\")\n",
    "tsla_stock_info = stock_info_grab(\"TSLA\")\n",
    "spy_stock_info = stock_info_grab(\"SPY\")\n",
    "aapl_stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>Nov. 9, 2020 at 4:30 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>Nov. 9, 2020 at 1:45 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>Nov. 9, 2020 at 1:18 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>Nov. 6, 2020 at 9:21 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>Nov. 7, 2020 at 8:49 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>Aug. 29, 2016 at 11:47 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>Aug. 29, 2016 at 9:41 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>Aug. 28, 2016 at 9:15 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>Aug. 27, 2016 at 11:02 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>Aug. 27, 2016 at 10:08 a.m. ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  \\\n",
       "0     Apple Inc. stock falls Monday, underperforms m...   \n",
       "1     Big Tech Stocks Are Lagging Today. Why They’ll...   \n",
       "2     As Apple releases its new line of Macs, the bi...   \n",
       "3     In the Midst of Election Uncertainty, Younger ...   \n",
       "4     Berkshire Buybacks Hit Record $9 Billion in Th...   \n",
       "...                                                 ...   \n",
       "9868  Respect for America has climbed during the Oba...   \n",
       "9869  Fitbit upgrades now track yoga, weightlifting ...   \n",
       "9870  5 things Tim Cook has done better at Apple tha...   \n",
       "9871  Want to invest in self-driving cars? Check out...   \n",
       "9872  As Apple’s ‘death cross’ turns 1, the stock he...   \n",
       "\n",
       "                                Date  \n",
       "0       Nov. 9, 2020 at 4:30 p.m. ET  \n",
       "1       Nov. 9, 2020 at 1:45 p.m. ET  \n",
       "2       Nov. 9, 2020 at 1:18 p.m. ET  \n",
       "3       Nov. 6, 2020 at 9:21 p.m. ET  \n",
       "4       Nov. 7, 2020 at 8:49 a.m. ET  \n",
       "...                              ...  \n",
       "9868  Aug. 29, 2016 at 11:47 a.m. ET  \n",
       "9869   Aug. 29, 2016 at 9:41 a.m. ET  \n",
       "9870   Aug. 28, 2016 at 9:15 p.m. ET  \n",
       "9871  Aug. 27, 2016 at 11:02 a.m. ET  \n",
       "9872  Aug. 27, 2016 at 10:08 a.m. ET  \n",
       "\n",
       "[9873 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_file = Path('../Resources/AAPL_HEADLINES.csv')\n",
    "#amzn_file = Path('../Resources/AMZN_HEADLINES.csv')\n",
    "spy_file = Path('../Resources/SPY_HEADLINES.csv')\n",
    "tsla_file = Path('../Resources/TSLA_HEADLINES.csv')\n",
    "\n",
    "aapl_headlines_df = pd.read_csv(aapl_file)\n",
    "#amzn_headlines_df = pd.read_csv(amzn_file)\n",
    "spy_headlines_df = pd.read_csv(spy_file)\n",
    "tsla_headlines_df = pd.read_csv(tsla_file)\n",
    "\n",
    "#aapl_headlines['Date'] = pd.to_datetime(aapl_headlines['Date']).dt.strftime('%Y-%m-%d')\n",
    "#aapl_headlines = aapl_headlines.set_index('Date')\n",
    "aapl_headlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_df(df):\n",
    "    \"\"\"\n",
    "    Takes headlines DataFrame & creates DataFrame with Sentiment columns.\n",
    "    Splits Date & Time, creates Time column and moves Date to Index.\n",
    "    \"\"\"\n",
    "    title_sent = {\n",
    "        \"compound\": [],\n",
    "        \"positive\": [],\n",
    "        \"neutral\": [],\n",
    "        \"negative\": [],\n",
    "        \"sentiment\": [],\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Sentiment scoring with VADER\n",
    "            title_sentiment = analyzer.polarity_scores(row[\"Headline\"])\n",
    "            title_sent[\"compound\"].append(title_sentiment[\"compound\"])\n",
    "            title_sent[\"positive\"].append(title_sentiment[\"pos\"])\n",
    "            title_sent[\"neutral\"].append(title_sentiment[\"neu\"])\n",
    "            title_sent[\"negative\"].append(title_sentiment[\"neg\"])\n",
    "            title_sent[\"sentiment\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    title_sent_df = pd.DataFrame(title_sent)\n",
    "    #title_sent_df.head()\n",
    "\n",
    "    headline_sentiment_df = df.join(title_sent_df)\n",
    "    headline_sentiment_df.dropna()\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.replace('at','-')\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.split('-').str[0]\n",
    "    headline_sentiment_df = headline_sentiment_df.reindex(columns=['Date', 'Headline', 'compound', 'positive', 'neutral', 'negative', 'sentiment'])\n",
    "    headline_sentiment_df['Date'] = pd.to_datetime(headline_sentiment_df['Date'])\n",
    "    headline_sentiment_df.set_index('Date')\n",
    "    return headline_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                           Headline  compound  \\\n",
       "0    2020-11-09  Apple Inc. stock falls Monday, underperforms m...    0.0000   \n",
       "1    2020-11-09  Big Tech Stocks Are Lagging Today. Why They’ll...   -0.0772   \n",
       "2    2020-11-09  As Apple releases its new line of Macs, the bi...    0.4767   \n",
       "3    2020-11-06  In the Midst of Election Uncertainty, Younger ...   -0.3400   \n",
       "4    2020-11-07  Berkshire Buybacks Hit Record $9 Billion in Th...   -0.1531   \n",
       "...         ...                                                ...       ...   \n",
       "9868 2016-08-29  Respect for America has climbed during the Oba...    0.4767   \n",
       "9869 2016-08-29  Fitbit upgrades now track yoga, weightlifting ...    0.0000   \n",
       "9870 2016-08-28  5 things Tim Cook has done better at Apple tha...    0.4404   \n",
       "9871 2016-08-27  Want to invest in self-driving cars? Check out...    0.0772   \n",
       "9872 2016-08-27  As Apple’s ‘death cross’ turns 1, the stock he...    0.0000   \n",
       "\n",
       "      positive  neutral  negative  sentiment  \n",
       "0        0.000    1.000     0.000          0  \n",
       "1        0.121    0.738     0.141         -1  \n",
       "2        0.193    0.807     0.000          1  \n",
       "3        0.000    0.806     0.194         -1  \n",
       "4        0.000    0.882     0.118         -1  \n",
       "...        ...      ...       ...        ...  \n",
       "9868     0.279    0.721     0.000          1  \n",
       "9869     0.000    1.000     0.000          0  \n",
       "9870     0.209    0.791     0.000          1  \n",
       "9871     0.126    0.874     0.000          1  \n",
       "9872     0.000    1.000     0.000          0  \n",
       "\n",
       "[9873 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_headlines = create_sentiment_df(aapl_headlines_df)\n",
    "#amzn_headlines = create_sentiment_df(amzn_headlines_df)\n",
    "tsla_headlines = create_sentiment_df(tsla_headlines_df)\n",
    "spy_headlines = create_sentiment_df(spy_headlines_df)\n",
    "aapl_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average sentiment score by date\n",
    "aapl_scores = aapl_headlines.groupby('Date').mean().sort_values(by='Date')\n",
    "#amzn_scores = amzn_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "tsla_scores = tsla_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "spy_scores = spy_headlines.groupby(['Date']).mean().sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment\n",
       "Date                                                         \n",
       "2016-03-19  0.836000  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.038600  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.440400  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.067100  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment\n",
       "Date                                               \n",
       "2016-03-19  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909\n",
       "...              ...       ...       ...        ...\n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000\n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333\n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000\n",
       "2020-11-07  0.000000  0.882000  0.118000  -1.000000\n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000\n",
       "\n",
       "[1410 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_scores = aapl_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "#amzn_scores = amzn_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "tsla_scores = tsla_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "spy_scores = spy_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "aapl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change\n",
       "Date                                                                    \n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909  105.990   -0.007770\n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132\n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843\n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369\n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278\n",
       "...              ...       ...       ...        ...      ...         ...\n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756\n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359\n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236\n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563\n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent scores distribution across each df poss use histogram, calc meanstd, or percentiles \n",
    "aapl_complete = pd.concat([aapl_scores,aapl_stock_info], join='outer', axis=1).dropna()\n",
    "#amzn_complete = pd.concat([amzn_scores,amzn_stock_info], join='outer', axis=1).dropna()\n",
    "tsla_complete = pd.concat([tsla_scores,tsla_stock_info], join='outer', axis=1).dropna()\n",
    "spy_complete = pd.concat([spy_scores,spy_stock_info], join='outer', axis=1).dropna()\n",
    "aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: shift aapl_complete['pct change'] one day on all dfs\n",
    "# TO DO: dropna() on all df['predicted pct change'] cols \n",
    "aapl_complete['predicted pct change'] = aapl_complete['pct change'].shift(periods=-1)\n",
    "#amzn_complete['predicted pct change'] = amzn_complete['pct change'].shift(periods=-1)\n",
    "tsla_complete['predicted pct change'] = tsla_complete['pct change'].shift(periods=-1)\n",
    "spy_complete['predicted pct change'] = spy_complete['pct change'].shift(periods=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "      <th>predicted pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change  \\\n",
       "Date                                                                       \n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909  105.990   -0.007770   \n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132   \n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843   \n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369   \n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278   \n",
       "...              ...       ...       ...        ...      ...         ...   \n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756   \n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359   \n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236   \n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563   \n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927   \n",
       "\n",
       "            predicted pct change  \n",
       "Date                              \n",
       "2016-08-30              0.001132  \n",
       "2016-08-31              0.005843  \n",
       "2016-09-01              0.009369  \n",
       "2016-09-02             -0.000278  \n",
       "2016-09-06              0.006221  \n",
       "...                          ...  \n",
       "2020-11-03              0.041359  \n",
       "2020-11-04              0.035236  \n",
       "2020-11-05             -0.002563  \n",
       "2020-11-06             -0.019927  \n",
       "2020-11-09                   NaN  \n",
       "\n",
       "[1052 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "y = df[\"status\"]\n",
    "X = df.drop(columns=\"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the train_test_split function to create training and testing subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a linear SVM model\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Score the model using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6133333333333333\n",
      "Testing Data Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Score the accuracy\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction   Actual\n",
       "0    approve     deny\n",
       "1       deny  approve\n",
       "2       deny     deny\n",
       "3    approve     deny\n",
       "4       deny     deny"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the test data\n",
    "predictions = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\n",
    "    \"Prediction\": predictions, \n",
    "    \"Actual\": y_test\n",
    "}).reset_index(drop=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 5],\n",
       "       [5, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.58      0.58      0.58        12\n",
      "        deny       0.62      0.62      0.62        13\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.60      0.60      0.60        25\n",
      "weighted avg       0.60      0.60      0.60        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09090909],\n",
       "       [-0.2       ],\n",
       "       [ 0.125     ],\n",
       "       [-0.28571429],\n",
       "       [ 0.25      ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features data\n",
    "#X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"pct change\"])\n",
    "\n",
    "\n",
    "#X[:5]\n",
    "\n",
    "X = df.copy()\n",
    "X =df['sentiment'].values\n",
    "#X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"close\", \"pct change\", \"predicted pct change\"]).values\n",
    "X = X.reshape(-1, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00777008],\n",
       "       [ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target data\n",
    "y = df[\"pct change\"].values\n",
    "#y = df[\"pct change\"].shift(periods=1).values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 4\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.0025\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.0038\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.0038\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.0038\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0038\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0038\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0038 \n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.0038\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.0038e+ - ETA: 0s - loss: 0.0296 - accuracy: 0.0045      \n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.0038\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.0038\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.0038\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.0038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.0038 \n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.0038   \n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.0038\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.0038 \n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.0038    \n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.0038 - ETA: 0s - loss: 0.0070 - accuracy: 0.0035   \n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.0038 \n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.0038     \n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.0038 \n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.0038 \n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.0038 \n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe with the history dictionary\n",
    "df_plot = pd.DataFrame(model.history, index=range(1, len(model.history[\"loss\"]) + 1))\n",
    "\n",
    "# Plot the loss\n",
    "df_plot.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "df_plot.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0162 - accuracy: 0.0000e+00\n",
      "Loss: 0.016187742352485657, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with \"Hard Sigmoid\" activation\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 120\n",
    "\n",
    "nn_2 = Sequential()\n",
    "nn_2.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"tanh\"))\n",
    "nn_2.add(Dense(units=1, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.0038\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: -0.0012 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038    \n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0377 - accuracy: 0.0000e+00\n",
      "Loss: 0.037722621113061905, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss_2, model_accuracy_2 = nn_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss_2}, Accuracy: {model_accuracy_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"pct change\"]\n",
    "X = df.drop(columns=\"pct change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c9d8dbe3fb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                    stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1669\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[-0.00777008  0.00113218  0.00584299  0.00936944 -0.00027847]\n",
      " [ 0.00113218  0.00584299  0.00936944 -0.00027847  0.00622098]\n",
      " [ 0.00584299  0.00936944 -0.00027847  0.00622098 -0.02639107]\n",
      " [ 0.00936944 -0.00027847  0.00622098 -0.02639107 -0.02246233]\n",
      " [-0.00027847  0.00622098 -0.02639107 -0.02246233  0.02229979]] \n",
      "\n",
      "y sample values:\n",
      "[[ 0.00622098]\n",
      " [-0.02639107]\n",
      " [-0.02246233]\n",
      " [ 0.02229979]\n",
      " [ 0.02446889]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 6\n",
    "target_column = 6\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = aapl_complete[\"Headline\"].values\n",
    "#y = aapl_sentiment[\"close\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>-0.043420</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>-0.087129</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.304967</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment    close\n",
       "Date                                                                  \n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909  105.990\n",
       "2016-08-31 -0.043420  0.070400  0.818600  0.111000  -0.200000  106.110\n",
       "2016-09-01  0.009625  0.069625  0.897625  0.032750   0.125000  106.730\n",
       "2016-09-02 -0.087129  0.063143  0.845429  0.091429  -0.285714  107.730\n",
       "2016-09-06  0.093200  0.131750  0.804500  0.063750   0.250000  107.700\n",
       "...              ...       ...       ...       ...        ...      ...\n",
       "2020-11-03  0.181500  0.119000  0.842000  0.038833   0.500000  110.375\n",
       "2020-11-04 -0.038410  0.078900  0.800900  0.120300  -0.300000  114.940\n",
       "2020-11-05  0.304967  0.202333  0.747333  0.050333   0.333333  118.990\n",
       "2020-11-06 -0.099333  0.054833  0.845500  0.099500  -0.500000  118.685\n",
       "2020-11-09  0.133167  0.104667  0.848333  0.047000   0.000000  116.320\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "x_cols = [i for i in aapl_complete.columns if i not in (\"pct change\")]\n",
    "X = aapl_complete[x_cols]\n",
    "y = aapl_complete[\"pct change\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "#tokenizer = Tokenizer(lower=True)\n",
    "#tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "#for token in list(tokenizer.word_index)[:5]:\n",
    "    #print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "#X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "#print(\"**Text comment**\")\n",
    "#print({X[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"**Numerical sequence representation**\")\n",
    "#print(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "#max_words = 30\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "#X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "#X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "#X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "#vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "#embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "#model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 64)            3328      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 1400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 4,734\n",
      "Trainable params: 4,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7537 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7529 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7302 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7189 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7071 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6854 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6844 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6521 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6619 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6189 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6395 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.5858 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6172 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5527 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5949 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5196 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5728 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4865 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5506 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4532 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ecc8dedd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN LSTM Accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-13207cb38487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrtix metrics from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rnn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dataframe to display confusion matrix from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_rnn_df = pd.DataFrame(\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve (AUC=1.0)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
