{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import tensorflow as tf\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\godz7\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv('ALPACA_API_KEY')\n",
    "alpaca_secret_key = os.getenv('ALPACA_SECRET_KEY')\n",
    "\n",
    "api = tradeapi.REST('PKYSIX5VD8DLHIZOILZS', 'Yv4AYGCNo9puqbXGPq2zF1sNrzy63CWCrWNJnOse', api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_info_grab(ticker):\n",
    "    \"\"\"\n",
    "    Takes ticker symbol and returns DataFrame with Date, Close, and Pct Change columns.\n",
    "    \"\"\"\n",
    "    # Set timeframe to '1D'\n",
    "    timeframe = \"1D\"\n",
    "\n",
    "    # Set current date and the date from one month ago using the ISO format\n",
    "    current_date = pd.Timestamp(\"2020-11-09\", tz=\"America/New_York\").isoformat()\n",
    "    past_date = pd.Timestamp(\"2016-08-27\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    df = api.get_barset(\n",
    "        ticker,\n",
    "        timeframe,\n",
    "        limit=None,\n",
    "        start=past_date,\n",
    "        end=current_date,\n",
    "        after=None,\n",
    "        until=None,\n",
    "    ).df\n",
    "    df = df.droplevel(axis=1, level=0)\n",
    "    df.index = df.index.date\n",
    "    df['pct change'] = df['close'].pct_change()\n",
    "    df['pct change'].dropna\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['open', 'high', 'low', 'volume'])\n",
    "    df = df.rename(columns={'index':'Date'})\n",
    "    df = df.set_index('Date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>106.8200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>105.9900</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>106.1100</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>106.7300</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>107.7300</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>107.7000</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>108.3700</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>105.5100</td>\n",
       "      <td>-0.026391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-09</th>\n",
       "      <td>103.1400</td>\n",
       "      <td>-0.022462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-12</th>\n",
       "      <td>105.4400</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-13</th>\n",
       "      <td>108.0200</td>\n",
       "      <td>0.024469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-14</th>\n",
       "      <td>111.7700</td>\n",
       "      <td>0.034716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-15</th>\n",
       "      <td>115.5700</td>\n",
       "      <td>0.033998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-16</th>\n",
       "      <td>114.9100</td>\n",
       "      <td>-0.005711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-19</th>\n",
       "      <td>113.5300</td>\n",
       "      <td>-0.012009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-20</th>\n",
       "      <td>113.5700</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-21</th>\n",
       "      <td>113.5300</td>\n",
       "      <td>-0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-22</th>\n",
       "      <td>114.6100</td>\n",
       "      <td>0.009513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-23</th>\n",
       "      <td>112.7049</td>\n",
       "      <td>-0.016622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-26</th>\n",
       "      <td>112.8700</td>\n",
       "      <td>0.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-27</th>\n",
       "      <td>113.1100</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-28</th>\n",
       "      <td>113.9500</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-29</th>\n",
       "      <td>112.1800</td>\n",
       "      <td>-0.015533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>113.0300</td>\n",
       "      <td>0.007577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-03</th>\n",
       "      <td>112.5100</td>\n",
       "      <td>-0.004601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-04</th>\n",
       "      <td>113.0200</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-05</th>\n",
       "      <td>113.0400</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-06</th>\n",
       "      <td>113.9100</td>\n",
       "      <td>0.007696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-07</th>\n",
       "      <td>114.0300</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-10</th>\n",
       "      <td>116.0500</td>\n",
       "      <td>0.017715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>114.1100</td>\n",
       "      <td>-0.007739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>115.6100</td>\n",
       "      <td>0.013145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>116.8000</td>\n",
       "      <td>0.010293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02</th>\n",
       "      <td>113.0200</td>\n",
       "      <td>-0.032363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05</th>\n",
       "      <td>116.5400</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-06</th>\n",
       "      <td>113.1600</td>\n",
       "      <td>-0.029003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-07</th>\n",
       "      <td>115.0500</td>\n",
       "      <td>0.016702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-08</th>\n",
       "      <td>114.9700</td>\n",
       "      <td>-0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-09</th>\n",
       "      <td>116.9800</td>\n",
       "      <td>0.017483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-12</th>\n",
       "      <td>124.4200</td>\n",
       "      <td>0.063601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-13</th>\n",
       "      <td>121.0500</td>\n",
       "      <td>-0.027086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-14</th>\n",
       "      <td>121.2900</td>\n",
       "      <td>0.001983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-15</th>\n",
       "      <td>120.7453</td>\n",
       "      <td>-0.004491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-16</th>\n",
       "      <td>118.9600</td>\n",
       "      <td>-0.014786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19</th>\n",
       "      <td>116.0000</td>\n",
       "      <td>-0.024882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20</th>\n",
       "      <td>117.5000</td>\n",
       "      <td>0.012931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>116.8600</td>\n",
       "      <td>-0.005447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>115.7737</td>\n",
       "      <td>-0.009296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23</th>\n",
       "      <td>115.0400</td>\n",
       "      <td>-0.006337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>115.0600</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>116.5300</td>\n",
       "      <td>0.012776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>111.1500</td>\n",
       "      <td>-0.046168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>114.5200</td>\n",
       "      <td>0.030319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>108.9000</td>\n",
       "      <td>-0.049074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02</th>\n",
       "      <td>108.7700</td>\n",
       "      <td>-0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>110.3750</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>114.9400</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>118.9900</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>118.6850</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>116.3200</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               close  pct change\n",
       "Date                            \n",
       "2016-08-29  106.8200         NaN\n",
       "2016-08-30  105.9900   -0.007770\n",
       "2016-08-31  106.1100    0.001132\n",
       "2016-09-01  106.7300    0.005843\n",
       "2016-09-02  107.7300    0.009369\n",
       "2016-09-06  107.7000   -0.000278\n",
       "2016-09-07  108.3700    0.006221\n",
       "2016-09-08  105.5100   -0.026391\n",
       "2016-09-09  103.1400   -0.022462\n",
       "2016-09-12  105.4400    0.022300\n",
       "2016-09-13  108.0200    0.024469\n",
       "2016-09-14  111.7700    0.034716\n",
       "2016-09-15  115.5700    0.033998\n",
       "2016-09-16  114.9100   -0.005711\n",
       "2016-09-19  113.5300   -0.012009\n",
       "2016-09-20  113.5700    0.000352\n",
       "2016-09-21  113.5300   -0.000352\n",
       "2016-09-22  114.6100    0.009513\n",
       "2016-09-23  112.7049   -0.016622\n",
       "2016-09-26  112.8700    0.001465\n",
       "2016-09-27  113.1100    0.002126\n",
       "2016-09-28  113.9500    0.007426\n",
       "2016-09-29  112.1800   -0.015533\n",
       "2016-09-30  113.0300    0.007577\n",
       "2016-10-03  112.5100   -0.004601\n",
       "2016-10-04  113.0200    0.004533\n",
       "2016-10-05  113.0400    0.000177\n",
       "2016-10-06  113.9100    0.007696\n",
       "2016-10-07  114.0300    0.001053\n",
       "2016-10-10  116.0500    0.017715\n",
       "...              ...         ...\n",
       "2020-09-29  114.1100   -0.007739\n",
       "2020-09-30  115.6100    0.013145\n",
       "2020-10-01  116.8000    0.010293\n",
       "2020-10-02  113.0200   -0.032363\n",
       "2020-10-05  116.5400    0.031145\n",
       "2020-10-06  113.1600   -0.029003\n",
       "2020-10-07  115.0500    0.016702\n",
       "2020-10-08  114.9700   -0.000695\n",
       "2020-10-09  116.9800    0.017483\n",
       "2020-10-12  124.4200    0.063601\n",
       "2020-10-13  121.0500   -0.027086\n",
       "2020-10-14  121.2900    0.001983\n",
       "2020-10-15  120.7453   -0.004491\n",
       "2020-10-16  118.9600   -0.014786\n",
       "2020-10-19  116.0000   -0.024882\n",
       "2020-10-20  117.5000    0.012931\n",
       "2020-10-21  116.8600   -0.005447\n",
       "2020-10-22  115.7737   -0.009296\n",
       "2020-10-23  115.0400   -0.006337\n",
       "2020-10-26  115.0600    0.000174\n",
       "2020-10-27  116.5300    0.012776\n",
       "2020-10-28  111.1500   -0.046168\n",
       "2020-10-29  114.5200    0.030319\n",
       "2020-10-30  108.9000   -0.049074\n",
       "2020-11-02  108.7700   -0.001194\n",
       "2020-11-03  110.3750    0.014756\n",
       "2020-11-04  114.9400    0.041359\n",
       "2020-11-05  118.9900    0.035236\n",
       "2020-11-06  118.6850   -0.002563\n",
       "2020-11-09  116.3200   -0.019927\n",
       "\n",
       "[1058 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_stock_info = stock_info_grab(\"AAPL\")\n",
    "amzn_stock_info = stock_info_grab(\"AMZN\")\n",
    "tsla_stock_info = stock_info_grab(\"TSLA\")\n",
    "spy_stock_info = stock_info_grab(\"SPY\")\n",
    "aapl_stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>Nov. 9, 2020 at 4:30 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>Nov. 9, 2020 at 1:45 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>Nov. 9, 2020 at 1:18 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>Nov. 6, 2020 at 9:21 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>Nov. 7, 2020 at 8:49 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>Aug. 29, 2016 at 11:47 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>Aug. 29, 2016 at 9:41 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>Aug. 28, 2016 at 9:15 p.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>Aug. 27, 2016 at 11:02 a.m. ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>Aug. 27, 2016 at 10:08 a.m. ET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  \\\n",
       "0     Apple Inc. stock falls Monday, underperforms m...   \n",
       "1     Big Tech Stocks Are Lagging Today. Why They’ll...   \n",
       "2     As Apple releases its new line of Macs, the bi...   \n",
       "3     In the Midst of Election Uncertainty, Younger ...   \n",
       "4     Berkshire Buybacks Hit Record $9 Billion in Th...   \n",
       "...                                                 ...   \n",
       "9868  Respect for America has climbed during the Oba...   \n",
       "9869  Fitbit upgrades now track yoga, weightlifting ...   \n",
       "9870  5 things Tim Cook has done better at Apple tha...   \n",
       "9871  Want to invest in self-driving cars? Check out...   \n",
       "9872  As Apple’s ‘death cross’ turns 1, the stock he...   \n",
       "\n",
       "                                Date  \n",
       "0       Nov. 9, 2020 at 4:30 p.m. ET  \n",
       "1       Nov. 9, 2020 at 1:45 p.m. ET  \n",
       "2       Nov. 9, 2020 at 1:18 p.m. ET  \n",
       "3       Nov. 6, 2020 at 9:21 p.m. ET  \n",
       "4       Nov. 7, 2020 at 8:49 a.m. ET  \n",
       "...                              ...  \n",
       "9868  Aug. 29, 2016 at 11:47 a.m. ET  \n",
       "9869   Aug. 29, 2016 at 9:41 a.m. ET  \n",
       "9870   Aug. 28, 2016 at 9:15 p.m. ET  \n",
       "9871  Aug. 27, 2016 at 11:02 a.m. ET  \n",
       "9872  Aug. 27, 2016 at 10:08 a.m. ET  \n",
       "\n",
       "[9873 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_file = Path('../Resources/AAPL_HEADLINES.csv')\n",
    "#amzn_file = Path('../Resources/AMZN_HEADLINES.csv')\n",
    "spy_file = Path('../Resources/SPY_HEADLINES.csv')\n",
    "tsla_file = Path('../Resources/TSLA_HEADLINES.csv')\n",
    "\n",
    "aapl_headlines_df = pd.read_csv(aapl_file)\n",
    "#amzn_headlines_df = pd.read_csv(amzn_file)\n",
    "spy_headlines_df = pd.read_csv(spy_file)\n",
    "tsla_headlines_df = pd.read_csv(tsla_file)\n",
    "\n",
    "#aapl_headlines['Date'] = pd.to_datetime(aapl_headlines['Date']).dt.strftime('%Y-%m-%d')\n",
    "#aapl_headlines = aapl_headlines.set_index('Date')\n",
    "aapl_headlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_df(df):\n",
    "    \"\"\"\n",
    "    Takes headlines DataFrame & creates DataFrame with Sentiment columns.\n",
    "    Splits Date & Time, creates Time column and moves Date to Index.\n",
    "    \"\"\"\n",
    "    title_sent = {\n",
    "        \"compound\": [],\n",
    "        \"positive\": [],\n",
    "        \"neutral\": [],\n",
    "        \"negative\": [],\n",
    "        \"sentiment\": [],\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            # Sentiment scoring with VADER\n",
    "            title_sentiment = analyzer.polarity_scores(row[\"Headline\"])\n",
    "            title_sent[\"compound\"].append(title_sentiment[\"compound\"])\n",
    "            title_sent[\"positive\"].append(title_sentiment[\"pos\"])\n",
    "            title_sent[\"neutral\"].append(title_sentiment[\"neu\"])\n",
    "            title_sent[\"negative\"].append(title_sentiment[\"neg\"])\n",
    "            title_sent[\"sentiment\"].append(get_sentiment(title_sentiment[\"compound\"]))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    title_sent_df = pd.DataFrame(title_sent)\n",
    "    #title_sent_df.head()\n",
    "\n",
    "    headline_sentiment_df = df.join(title_sent_df)\n",
    "    headline_sentiment_df.dropna()\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.replace('at','-')\n",
    "    headline_sentiment_df['Date'] = headline_sentiment_df['Date'].str.split('-').str[0]\n",
    "    headline_sentiment_df = headline_sentiment_df.reindex(columns=['Date', 'Headline', 'compound', 'positive', 'neutral', 'negative', 'sentiment'])\n",
    "    headline_sentiment_df['Date'] = pd.to_datetime(headline_sentiment_df['Date'])\n",
    "    headline_sentiment_df.set_index('Date')\n",
    "    return headline_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Apple Inc. stock falls Monday, underperforms m...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>Big Tech Stocks Are Lagging Today. Why They’ll...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>As Apple releases its new line of Macs, the bi...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>In the Midst of Election Uncertainty, Younger ...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>Berkshire Buybacks Hit Record $9 Billion in Th...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Respect for America has climbed during the Oba...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Fitbit upgrades now track yoga, weightlifting ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>5 things Tim Cook has done better at Apple tha...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>Want to invest in self-driving cars? Check out...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>As Apple’s ‘death cross’ turns 1, the stock he...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9873 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                           Headline  compound  \\\n",
       "0    2020-11-09  Apple Inc. stock falls Monday, underperforms m...    0.0000   \n",
       "1    2020-11-09  Big Tech Stocks Are Lagging Today. Why They’ll...   -0.0772   \n",
       "2    2020-11-09  As Apple releases its new line of Macs, the bi...    0.4767   \n",
       "3    2020-11-06  In the Midst of Election Uncertainty, Younger ...   -0.3400   \n",
       "4    2020-11-07  Berkshire Buybacks Hit Record $9 Billion in Th...   -0.1531   \n",
       "...         ...                                                ...       ...   \n",
       "9868 2016-08-29  Respect for America has climbed during the Oba...    0.4767   \n",
       "9869 2016-08-29  Fitbit upgrades now track yoga, weightlifting ...    0.0000   \n",
       "9870 2016-08-28  5 things Tim Cook has done better at Apple tha...    0.4404   \n",
       "9871 2016-08-27  Want to invest in self-driving cars? Check out...    0.0772   \n",
       "9872 2016-08-27  As Apple’s ‘death cross’ turns 1, the stock he...    0.0000   \n",
       "\n",
       "      positive  neutral  negative  sentiment  \n",
       "0        0.000    1.000     0.000          0  \n",
       "1        0.121    0.738     0.141         -1  \n",
       "2        0.193    0.807     0.000          1  \n",
       "3        0.000    0.806     0.194         -1  \n",
       "4        0.000    0.882     0.118         -1  \n",
       "...        ...      ...       ...        ...  \n",
       "9868     0.279    0.721     0.000          1  \n",
       "9869     0.000    1.000     0.000          0  \n",
       "9870     0.209    0.791     0.000          1  \n",
       "9871     0.126    0.874     0.000          1  \n",
       "9872     0.000    1.000     0.000          0  \n",
       "\n",
       "[9873 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_headlines = create_sentiment_df(aapl_headlines_df)\n",
    "#amzn_headlines = create_sentiment_df(amzn_headlines_df)\n",
    "tsla_headlines = create_sentiment_df(tsla_headlines_df)\n",
    "spy_headlines = create_sentiment_df(spy_headlines_df)\n",
    "aapl_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average sentiment score by date\n",
    "aapl_scores = aapl_headlines.groupby('Date').mean().sort_values(by='Date')\n",
    "#amzn_scores = amzn_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "tsla_scores = tsla_headlines.groupby(['Date']).mean().sort_values(by='Date')\n",
    "spy_scores = spy_headlines.groupby(['Date']).mean().sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment\n",
       "Date                                                         \n",
       "2016-03-19  0.836000  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.038600  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.440400  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.067100  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-27</th>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-28</th>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-29</th>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.842286</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment\n",
       "Date                                               \n",
       "2016-03-19  0.530000  0.470000  0.000000   1.000000\n",
       "2016-08-27  0.063000  0.937000  0.000000   0.500000\n",
       "2016-08-28  0.209000  0.791000  0.000000   1.000000\n",
       "2016-08-29  0.102000  0.842286  0.055714   0.000000\n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909\n",
       "...              ...       ...       ...        ...\n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000\n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333\n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000\n",
       "2020-11-07  0.000000  0.882000  0.118000  -1.000000\n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000\n",
       "\n",
       "[1410 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_scores = aapl_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "#amzn_scores = amzn_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "tsla_scores = tsla_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "spy_scores = spy_scores[['positive', 'neutral', 'negative', 'sentiment']]\n",
    "aapl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change\n",
       "Date                                                                    \n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909  105.990   -0.007770\n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132\n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843\n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369\n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278\n",
       "...              ...       ...       ...        ...      ...         ...\n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756\n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359\n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236\n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563\n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent scores distribution across each df poss use histogram, calc meanstd, or percentiles \n",
    "aapl_complete = pd.concat([aapl_scores,aapl_stock_info], join='outer', axis=1).dropna()\n",
    "#amzn_complete = pd.concat([amzn_scores,amzn_stock_info], join='outer', axis=1).dropna()\n",
    "tsla_complete = pd.concat([tsla_scores,tsla_stock_info], join='outer', axis=1).dropna()\n",
    "spy_complete = pd.concat([spy_scores,spy_stock_info], join='outer', axis=1).dropna()\n",
    "aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: shift aapl_complete['pct change'] one day on all dfs\n",
    "# TO DO: dropna() on all df['predicted pct change'] cols \n",
    "aapl_complete['predicted pct change'] = aapl_complete['pct change'].shift(periods=-1)\n",
    "#amzn_complete['predicted pct change'] = amzn_complete['pct change'].shift(periods=-1)\n",
    "tsla_complete['predicted pct change'] = tsla_complete['pct change'].shift(periods=-1)\n",
    "spy_complete['predicted pct change'] = spy_complete['pct change'].shift(periods=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>pct change</th>\n",
       "      <th>predicted pct change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "      <td>-0.007770</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.005843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.035236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>-0.002563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.019927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "      <td>-0.019927</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive   neutral  negative  sentiment    close  pct change  \\\n",
       "Date                                                                       \n",
       "2016-08-30  0.061591  0.883455  0.054955  -0.090909  105.990   -0.007770   \n",
       "2016-08-31  0.070400  0.818600  0.111000  -0.200000  106.110    0.001132   \n",
       "2016-09-01  0.069625  0.897625  0.032750   0.125000  106.730    0.005843   \n",
       "2016-09-02  0.063143  0.845429  0.091429  -0.285714  107.730    0.009369   \n",
       "2016-09-06  0.131750  0.804500  0.063750   0.250000  107.700   -0.000278   \n",
       "...              ...       ...       ...        ...      ...         ...   \n",
       "2020-11-03  0.119000  0.842000  0.038833   0.500000  110.375    0.014756   \n",
       "2020-11-04  0.078900  0.800900  0.120300  -0.300000  114.940    0.041359   \n",
       "2020-11-05  0.202333  0.747333  0.050333   0.333333  118.990    0.035236   \n",
       "2020-11-06  0.054833  0.845500  0.099500  -0.500000  118.685   -0.002563   \n",
       "2020-11-09  0.104667  0.848333  0.047000   0.000000  116.320   -0.019927   \n",
       "\n",
       "            predicted pct change  \n",
       "Date                              \n",
       "2016-08-30              0.001132  \n",
       "2016-08-31              0.005843  \n",
       "2016-09-01              0.009369  \n",
       "2016-09-02             -0.000278  \n",
       "2016-09-06              0.006221  \n",
       "...                          ...  \n",
       "2020-11-03              0.041359  \n",
       "2020-11-04              0.035236  \n",
       "2020-11-05             -0.002563  \n",
       "2020-11-06             -0.019927  \n",
       "2020-11-09                   NaN  \n",
       "\n",
       "[1052 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06159091,  0.88345455,  0.05495455, -0.09090909],\n",
       "       [ 0.0704    ,  0.8186    ,  0.111     , -0.2       ],\n",
       "       [ 0.069625  ,  0.897625  ,  0.03275   ,  0.125     ],\n",
       "       [ 0.06314286,  0.84542857,  0.09142857, -0.28571429],\n",
       "       [ 0.13175   ,  0.8045    ,  0.06375   ,  0.25      ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features data\n",
    "#X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"pct change\"])\n",
    "\n",
    "\n",
    "#X[:5]\n",
    "\n",
    "X = df.copy()\n",
    "X = df[['positive', 'neutral', 'negative','sentiment']].values\n",
    "#X = X.drop(columns=[\"close\", \"pct change\", \"predicted pct change\"]).values\n",
    "#X = X.reshape(-1, 1)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00113218],\n",
       "       [ 0.00584299],\n",
       "       [ 0.00936944],\n",
       "       [-0.00027847],\n",
       "       [ 0.00622098]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target data\n",
    "y = df[\"predicted pct change\"].values\n",
    "#y = df[\"pct change\"].shift(periods=-1).values\n",
    "y = y.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "number_inputs = 4\n",
    "number_hidden_nodes = 12\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"relu\"))\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1135 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9764 - accuracy: 0.0013\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8634 - accuracy: 0.0013\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7690 - accuracy: 0.0013\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.0013\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.0013\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.0013\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.0013\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.0013\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.0013\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.0013\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.0013\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.0013\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.0013\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.0013\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.0013\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.03 - 0s 1ms/step - loss: 0.2418 - accuracy: 0.0013\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.0013\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.0013\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.0013\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.0013\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.0013\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.0013\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.0013\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.0013\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.0013\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.0013\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.0013\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.0013\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.0013\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.0013\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.0013\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.0013\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.0013\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.0013\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0013\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.0013\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.0013\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.0013\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.0013\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.0013\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.0013\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.0013\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.0013\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.0013\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.0013\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.0013\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.0013\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.0013\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.0013\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.0013\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.0013\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.0013\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.0013\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.0013\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.0013\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.0013\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.0013\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.0013\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.0013\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.0013\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.0013\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.0013\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.0013\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.0013\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.0013\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.0013 \n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.0013 \n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.0013\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.0013 \n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.0013\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.0013\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.0013\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.0013\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.0013\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.0013\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.0013\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.0013\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.0013\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.0013\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.0013\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.0013\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.0013\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.0013\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.0013\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.0013\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.0013\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.0013\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.0013\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.0013 \n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.0013\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.0013 \n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.0013\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0122 - accuracy: 0.0013\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.0013\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.0013\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.0013 \n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.0013 \n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.0013\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.0013\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe with the history dictionary\n",
    "df_plot = pd.DataFrame(model.history, index=range(1, len(model.history[\"loss\"]) + 1))\n",
    "\n",
    "# Plot the loss\n",
    "df_plot.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "df_plot.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0161 - accuracy: 0.0000e+00\n",
      "Loss: 0.016056545078754425, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with \"Hard Sigmoid\" activation\n",
    "number_inputs = 1\n",
    "number_hidden_nodes = 120\n",
    "\n",
    "nn_2 = Sequential()\n",
    "nn_2.add(Dense(units=number_hidden_nodes, input_dim=number_inputs, activation=\"tanh\"))\n",
    "nn_2.add(Dense(units=1, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6263 - accuracy: 0.0038\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.0038\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.0038\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.0038\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.0038\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038 \n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.0038 - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_2 = nn_2.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 0.0377 - accuracy: 0.0000e+00\n",
      "Loss: 0.037722621113061905, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model fit with linear dummy data\n",
    "model_loss_2, model_accuracy_2 = nn_2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss_2}, Accuracy: {model_accuracy_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"pct change\"]\n",
    "X = df.drop(columns=\"pct change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c9d8dbe3fb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                    stratify=y)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1669\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1, \n",
    "                                                   stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aapl_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[-0.00777008  0.00113218  0.00584299  0.00936944 -0.00027847]\n",
      " [ 0.00113218  0.00584299  0.00936944 -0.00027847  0.00622098]\n",
      " [ 0.00584299  0.00936944 -0.00027847  0.00622098 -0.02639107]\n",
      " [ 0.00936944 -0.00027847  0.00622098 -0.02639107 -0.02246233]\n",
      " [-0.00027847  0.00622098 -0.02639107 -0.02246233  0.02229979]] \n",
      "\n",
      "y sample values:\n",
      "[[ 0.00622098]\n",
      " [-0.02639107]\n",
      " [-0.02246233]\n",
      " [ 0.02229979]\n",
      " [ 0.02446889]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 6\n",
    "target_column = 6\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = aapl_complete[\"Headline\"].values\n",
    "#y = aapl_sentiment[\"close\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-30</th>\n",
       "      <td>-0.015205</td>\n",
       "      <td>0.061591</td>\n",
       "      <td>0.883455</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>105.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>-0.043420</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>106.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.897625</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>106.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-02</th>\n",
       "      <td>-0.087129</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>107.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.804500</td>\n",
       "      <td>0.063750</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>107.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.038833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>110.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>-0.038410</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>114.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>0.304967</td>\n",
       "      <td>0.202333</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>118.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>118.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>0.133167</td>\n",
       "      <td>0.104667</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1052 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            compound  positive   neutral  negative  sentiment    close\n",
       "Date                                                                  \n",
       "2016-08-30 -0.015205  0.061591  0.883455  0.054955  -0.090909  105.990\n",
       "2016-08-31 -0.043420  0.070400  0.818600  0.111000  -0.200000  106.110\n",
       "2016-09-01  0.009625  0.069625  0.897625  0.032750   0.125000  106.730\n",
       "2016-09-02 -0.087129  0.063143  0.845429  0.091429  -0.285714  107.730\n",
       "2016-09-06  0.093200  0.131750  0.804500  0.063750   0.250000  107.700\n",
       "...              ...       ...       ...       ...        ...      ...\n",
       "2020-11-03  0.181500  0.119000  0.842000  0.038833   0.500000  110.375\n",
       "2020-11-04 -0.038410  0.078900  0.800900  0.120300  -0.300000  114.940\n",
       "2020-11-05  0.304967  0.202333  0.747333  0.050333   0.333333  118.990\n",
       "2020-11-06 -0.099333  0.054833  0.845500  0.099500  -0.500000  118.685\n",
       "2020-11-09  0.133167  0.104667  0.848333  0.047000   0.000000  116.320\n",
       "\n",
       "[1052 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "x_cols = [i for i in aapl_complete.columns if i not in (\"pct change\")]\n",
    "X = aapl_complete[x_cols]\n",
    "y = aapl_complete[\"pct change\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "#tokenizer = Tokenizer(lower=True)\n",
    "#tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "#for token in list(tokenizer.word_index)[:5]:\n",
    "    #print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "#X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "#print(\"**Text comment**\")\n",
    "#print({X[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"**Numerical sequence representation**\")\n",
    "#print(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "#max_words = 30\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "#X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "#X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "#X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "#vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "#embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "#model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 64)            3328      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 1400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 4,734\n",
      "Trainable params: 4,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7537 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7529 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7302 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.7189 - val_accuracy: 0.0000e+00 - val_tp: 1.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7071 - accuracy: 0.0000e+00 - tp: 1.0000 - tn: 0.0000e+00 - fp: 1.0000 - fn: 0.0000e+00 - precision: 0.5000 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.6854 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6844 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6521 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6619 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.6189 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6395 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - val_loss: 0.5858 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6172 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5527 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5949 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.5196 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5728 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4865 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5506 - accuracy: 0.5000 - tp: 0.0000e+00 - tn: 1.0000 - fp: 0.0000e+00 - fn: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.4532 - val_accuracy: 0.0000e+00 - val_tp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8ecc8dedd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN LSTM Accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-13207cb38487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrtix metrics from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rnn_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dataframe to display confusion matrix from the RNN LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m cm_rnn_df = pd.DataFrame(\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/luisaguilar/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve (AUC=1.0)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
